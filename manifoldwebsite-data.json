{
  "projects": {
    "fase": {
      "title": "Frontier AI System Evaluations",
      "description": "FASE. is an initiative to develop evolving, community-driven evaluation frameworks for AI. The project builds domain-specific benchmarks, simulators for autonomous AI systems, and methodological standards for rigorous assessment. By enabling open contribution and structured collaboration, FASE supports the creation of reliable, extensible testing grounds for advancing AI capabilities in complex environments.",
      "links": {},
      "image": "",
      "icon": ""
    },
    "vlm_calibration": {
      "title": "VLM Calibration",
      "description": "The VLM Calibration Project investigates whether large language models can accurately assess the correctness of their own answers. Despite impressive capabilities, VLMs often exhibit overconfidence; even when wrong. This project systematically evaluates model calibration across multiple datasets and architectures, probing the reliability of their self-assessed confidence. By analyzing when and why different models misjudge uncertainty, we aim to improve trust and interpretability in AI systems.",
      "links": {},
      "image": "manifoldWebsite-images/VLMCalibration.png",
      "icon": ""
    },
    "multimodal_action_models": {
      "title": "Multimodal Action Models",
      "description": "The Multimodal Action Models project aims to develop AI systems that link perception to action across diverse modalities such as vision, language and sensor data to perform complex tasks in dynamic physical and digital environments. These models integrate understanding and control into unified architectures, enabling generalist agents that can interpret multimodal inputs, reason about goals and take appropriate actions in real world or simulated settings.",
      "links": {},
      "image": "manifoldWebsite-images/MultimodalActionModels.png",
      "icon": ""
    },
    "multinet": {
      "title": "MultiNet",
      "description": "We are building unified benchmarks for AI systems that see, reason, and act. MultiNet standardizes diverse multimodal datasets, spanning vision, language, and action, and provides tools for training and evaluating generalist agents. By enabling consistent pretraining and rigorous end-to-end evaluation, MultiNet advances the development of foundation models capable of perception, understanding, and control.",
      "links": {},
      "image": "manifoldWebsite-images/MultiNet.png",
      "icon": ""
    },
    "modular_space_systems_assembly": {
      "title": "Modular Space Systems Assembly",
      "description": "Modular Space Systems Assembly develops guidance and control methods for swarms of robotic agents that autonomously assemble and reconfigure modular spacecraft in orbit. From free-flying cubes to electromagnetically actuated voxels, MSSA explores scalable algorithms for assembling complex structures without centralized control. This enables rapid in-orbit construction and dynamic reconfiguration of next-generation spacecraft and infrastructure.",
      "links": {},
      "image": "manifoldWebsite-images/MSSA.png",
      "icon": ""
    },
    "crowded_orbit_navigation": {
      "title": "Crowded Orbit Navigation",
      "description": "Crowded Orbits develops learning-based controllers for autonomous spacecraft swarms operating in dense orbits. Using a transformer based neural operator, the system learns to generate fuel-efficient maneuvers that avoid both debris and inter-agent collisions. The project leverages distribution-based objectives and orbital mechanics to enable scalable, decentralized navigation in increasingly congested orbital regimes.",
      "links": {},
      "image": "manifoldWebsite-images/CrowdedOrbitNavigation.png",
      "icon": ""
    }
  },
  "research_directions": {
    "golem": {
      "label": "Golem",
      "title": "GOLEM - Generalist Omnimodal Learning for Engineered Minds",
      "description": "GOLEM (Generalist Omnimodal Learning in Engineered Minds) is a long term research program focused on building AI systems that can perceive, reason, adapt, and act across any input and output modality. The program explores fundamental architectures, training methodologies, and evaluation frameworks needed for AI systems that can process multimodal inputs, generate appropriate outputs, adapt to new situations, and continue learning over time. Viewing minds as computational entities capable of goal-directed adaptive behavior, GOLEM addresses core questions about how AI systems can learn in real-time from sensorimotor experience and efficiently modify their internal architectures. The program encompasses multimodal intelligence and action research, metacognitive systems development, and living benchmarks initiatives, all working toward creating truly general artificial intelligence. Through this work, we aim to advance both the scientific understanding of intelligence and the practical deployment of AI systems that can operate effectively in open, uncertain environments.",
      "projects": {
        "fase": {
          "title": "Frontier AI System Evaluations",
          "description": "FASE. is an initiative to develop evolving, community-driven evaluation frameworks for AI.",
          "url": "/fase",
          "icon": ""
        },
        "vlm_calibration": {
          "title": "VLM Calibration",
          "description": "Evaluating how well vision language models know when they’re wrong.",
          "url": "/vlm_calibration",
          "icon": ""
        },
        "multimodal_action_models": {
          "title": "Multimodal Action Models",
          "description": "Connecting vision, language and control for generalist embodied AI",
          "url": "/multimodal_action_models",
          "icon": ""
        },
        "multinet": {
          "title": "MultiNet",
          "description": "Benchmarking next‑gen Generalist AI: multimodal perception, language, and action",
          "url": "/multinet",
          "icon": ""
        }
      },
      "image": "manifoldWebsite-images/GOLEM.png"
    },
    "aethermorph": {
      "label": "Aethermorph",
      "title": "Aethermorph",
      "description": "Aethermorph develops intelligent, reconfigurable swarms of modular spacecraft for autonomous construction and servicing in orbit. Unlike traditional space robotics, Aethermorph systems are designed to adapt in real time; physically reassembling, coordinating without central control, and responding to mission goals. Through decentralized learning, emergent behavior, and dynamic morphogenesis, the program lays the groundwork for scalable orbital infrastructure and resilient space operations.",
      "projects": {
        "modular_space_systems_assembly": {
          "title": "Modular Space Systems Assembly",
          "description": "Autonomous swarm assembly and reconfiguration of modular space structures.",
          "url": "/modular_space_systems_assembly",
          "icon": ""
        },
        "crowded_orbit_navigation": {
          "title": "Crowded Orbit Navigation",
          "description": "Neural operator control for collision-free swarm navigation in congested orbital environments.",
          "url": "/crowded_orbit_navigation",
          "icon": ""
        }
      },
      "image": "manifoldWebsite-images/Aethermorph.png"
    }
  }
}
